{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "import warnings\n",
    "from abc import abstractmethod\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import yaml\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.optim import Optimizer, lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Logger:\n",
    "    \"\"\"Customized logger.\n",
    "\n",
    "    Args:\n",
    "        logging_level: lowest-severity log message the logger handles\n",
    "        logging_file: file stream for logging\n",
    "            *Note: If `logging_file` isn't specified, message is only\n",
    "                logged to system standard output.\n",
    "    \"\"\"\n",
    "\n",
    "    _logger: logging.Logger = None\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        logging_level: str = \"INFO\",\n",
    "        logging_file: Optional[Path] = None,\n",
    "    ):\n",
    "        self.logging_level = logging_level\n",
    "        self.logging_file = logging_file\n",
    "\n",
    "        self._build_logger()\n",
    "\n",
    "    def get_logger(self) -> logging.Logger:\n",
    "        \"\"\"Return customized logger.\"\"\"\n",
    "        return self._logger\n",
    "\n",
    "    def _build_logger(self) -> None:\n",
    "        \"\"\"Build logger.\"\"\"\n",
    "        self._logger = logging.getLogger()\n",
    "        self._logger.setLevel(self._get_level())\n",
    "        self._add_handler()\n",
    "\n",
    "    def _get_level(self) -> int:\n",
    "        \"\"\"Return lowest severity of the events the logger handles.\n",
    "\n",
    "        Returns:\n",
    "            level: severity of the events\n",
    "        \"\"\"\n",
    "        level = 0\n",
    "\n",
    "        if self.logging_level == \"DEBUG\":\n",
    "            level = logging.DEBUG\n",
    "        elif self.logging_level == \"INFO\":\n",
    "            level = logging.INFO\n",
    "        elif self.logging_level == \"WARNING\":\n",
    "            level = logging.WARNING\n",
    "        elif self.logging_level == \"ERROR\":\n",
    "            level = logging.ERROR\n",
    "        elif self.logging_level == \"CRITICAL\":\n",
    "            level = logging.CRITICAL\n",
    "\n",
    "        return level\n",
    "\n",
    "    def _add_handler(self) -> None:\n",
    "        \"\"\"Add stream and file (optional) handlers to logger.\"\"\"\n",
    "        s_handler = logging.StreamHandler(sys.stdout)\n",
    "        self._logger.addHandler(s_handler)\n",
    "\n",
    "        if self.logging_file is not None:\n",
    "            f_handler = logging.FileHandler(self.logging_file, mode=\"a\")\n",
    "            self._logger.addHandler(f_handler)\n",
    "\n",
    "            \n",
    "def _seed_everything(seed: int) -> None:\n",
    "    \"\"\"Seed current experiment to guarantee reproducibility.\n",
    "\n",
    "    Args:\n",
    "        seed: manually specified seed number\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # When running with cudnn backend\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True \n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"/data2/users/koushani/HMS_data\")\n",
    "\n",
    "class CFG:\n",
    "    train_models = True\n",
    "    seed = 42\n",
    "    \n",
    "    exp_id = datetime.now().strftime(\"%m%d-%H-%M-%S\")\n",
    "    # Define experiment ID and path\n",
    "    exp_dump_path = Path(DATA_PATH/\"kaggle\"/\"working\"/exp_id)\n",
    "\n",
    "    # Create the directory\n",
    "    exp_dump_path.mkdir(parents=True, exist_ok=True)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # == Data ==\n",
    "    gen_eegs = False\n",
    "    # Chris' 8 channels\n",
    "    feats = [\n",
    "        \"Fp1\", \"T3\", \"C3\", \"O1\",\n",
    "        \"Fp2\", \"C4\", \"T4\", \"O2\"\n",
    "    ]\n",
    "    cast_eegs = True\n",
    "    dataset = {\n",
    "        \"eeg\": {\n",
    "            \"n_feats\": 8,\n",
    "            \"apply_chris_magic_ch8\": True,\n",
    "            \"normalize\": True,\n",
    "            \"apply_butter_lowpass_filter\": True,\n",
    "            \"apply_mu_law_encoding\": False,\n",
    "            \"downsample\": 5\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # == Trainer ==\n",
    "    trainer = {\n",
    "        \"epochs\": 5,\n",
    "        \"lr\": 1e-3,\n",
    "        \"dataloader\": {\n",
    "            \"batch_size\": 32,\n",
    "            \"shuffle\": True,\n",
    "            \"num_workers\": 2\n",
    "        },\n",
    "        \"use_amp\": True,\n",
    "        \"grad_accum_steps\": 1,\n",
    "        \"model_ckpt\": {\n",
    "            \"ckpt_metric\": \"kldiv\",\n",
    "            \"ckpt_mode\": \"min\",\n",
    "            \"best_ckpt_mid\": \"last\"\n",
    "        },\n",
    "        \"es\": {\"patience\": 0},\n",
    "        \"step_per_batch\": True,\n",
    "        \"one_batch_only\": False\n",
    "    }\n",
    "    \n",
    "    # == Debug ==\n",
    "    one_fold_only = True\n",
    "    \n",
    "    \n",
    "N_CLASSES = 6\n",
    "TGT_VOTE_COLS = [\n",
    "    \"seizure_vote\", \"lpd_vote\", \"gpd_vote\", \"lrda_vote\",\n",
    "    \"grda_vote\", \"other_vote\"\n",
    "]\n",
    "TGT_COL = \"target\"\n",
    "EEG_FREQ = 200  # Hz\n",
    "EEG_WLEN = 50  # sec\n",
    "EEG_PTS = int(EEG_FREQ * EEG_WLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.exp_dump_path.exists():\n",
    "    os.mkdir(CFG.exp_dump_path)\n",
    "    \n",
    "logger = _Logger(logging_file=CFG.exp_dump_path / \"train_eval.log\").get_logger()\n",
    "_seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_eeg_window(file: Path) -> np.ndarray:\n",
    "    \"\"\"Return cropped EEG window.\n",
    "\n",
    "    Default setting is to return the middle 50-sec window.\n",
    "\n",
    "    Args:\n",
    "        file: EEG file path\n",
    "        test: if True, there's no need to truncate EEGs\n",
    "\n",
    "    Returns:\n",
    "        eeg_win: cropped EEG window \n",
    "    \"\"\"\n",
    "    eeg = pd.read_parquet(file, columns=CFG.feats)\n",
    "    n_pts = len(eeg)\n",
    "    offset = (n_pts - EEG_PTS) // 2\n",
    "    eeg = eeg.iloc[offset:offset + EEG_PTS]\n",
    "    \n",
    "    eeg_win = np.zeros((EEG_PTS, len(CFG.feats)))\n",
    "    for j, col in enumerate(CFG.feats):\n",
    "        if CFG.cast_eegs:\n",
    "            eeg_raw = eeg[col].values.astype(\"float32\")\n",
    "        else:\n",
    "            eeg_raw = eeg[col].values \n",
    "\n",
    "        # Fill missing values\n",
    "        mean = np.nanmean(eeg_raw)\n",
    "        if np.isnan(eeg_raw).mean() < 1:\n",
    "            eeg_raw = np.nan_to_num(eeg_raw, nan=mean)\n",
    "        else: \n",
    "            # All missing\n",
    "            eeg_raw[:] = 0\n",
    "        eeg_win[:, j] = eeg_raw \n",
    "        \n",
    "    return eeg_win "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape | (106800, 15)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(DATA_PATH / \"train.csv\")\n",
    "logger.info(f\"Train data shape | {train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load cropped EEGs...\n",
      "Demo EEG shape | (10000, 8)\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "eeg_file_path = DATA_PATH/\"kaggle\" /\"input\"/ \"brain-eegs\" / \"eegs.npy\"\n",
    "\n",
    "# Ensure directories exist\n",
    "eeg_file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Unique EEG IDs\n",
    "uniq_eeg_ids = train[\"eeg_id\"].unique()\n",
    "n_uniq_eeg_ids = len(uniq_eeg_ids)\n",
    "\n",
    "logger.info(\"Load cropped EEGs...\")\n",
    "all_eegs = np.load(eeg_file_path, allow_pickle=True).item()\n",
    "assert len(all_eegs) == n_uniq_eeg_ids\n",
    "\n",
    "# Debug: Print a sample EEG shape\n",
    "logger.info(f\"Demo EEG shape | {list(all_eegs.values())[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process labels...\n",
      "Training DataFrame shape | (17089, 9)\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Process labels...\")\n",
    "df_tmp = train.groupby(\"eeg_id\")[[\"patient_id\"]].agg(\"first\")\n",
    "labels_tmp = train.groupby(\"eeg_id\")[TGT_VOTE_COLS].agg(\"sum\")\n",
    "for col in TGT_VOTE_COLS:\n",
    "    df_tmp[col] = labels_tmp[col].values\n",
    "\n",
    "# Normalize target columns\n",
    "y_data = df_tmp[TGT_VOTE_COLS].values\n",
    "y_data = y_data / y_data.sum(axis=1, keepdims=True)\n",
    "df_tmp[TGT_VOTE_COLS] = y_data\n",
    "\n",
    "tgt = train.groupby(\"eeg_id\")[[\"expert_consensus\"]].agg(\"first\")\n",
    "df_tmp[TGT_COL] = tgt \n",
    "\n",
    "train = df_tmp.reset_index()\n",
    "logger.info(f\"Training DataFrame shape | {train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _EEGTransformer(object):\n",
    "    \"\"\"Data transformer for raw EEG signals.\"\"\"\n",
    "\n",
    "    FEAT2CODE = {f: i for i, f in enumerate(CFG.feats)}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_feats: int,\n",
    "        apply_chris_magic_ch8: bool = True,\n",
    "        normalize: bool = True,\n",
    "        apply_butter_lowpass_filter: bool = True,\n",
    "        apply_mu_law_encoding: bool = False,\n",
    "        downsample: Optional[int] = None,\n",
    "    ) -> None:\n",
    "        self.n_feats = n_feats\n",
    "        self.apply_chris_magic_ch8 = apply_chris_magic_ch8\n",
    "        self.normalize = normalize\n",
    "        self.apply_butter_lowpass_filter = apply_butter_lowpass_filter\n",
    "        self.apply_mu_law_encoding = apply_mu_law_encoding\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def transform(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply transformation on raw EEG signals.\n",
    "        \n",
    "        Args:\n",
    "            x: raw EEG signals, with shape (L, C)\n",
    "\n",
    "        Return:\n",
    "            x_: transformed EEG signals\n",
    "        \"\"\"\n",
    "        x_ = x.copy()\n",
    "        if self.apply_chris_magic_ch8:\n",
    "            x_ = self._apply_chris_magic_ch8(x_)\n",
    "\n",
    "        if self.normalize:\n",
    "            x_ = np.clip(x_, -1024, 1024)\n",
    "            x_ = np.nan_to_num(x_, nan=0) / 32.0\n",
    "\n",
    "        if self.apply_butter_lowpass_filter:\n",
    "            x_ = self._butter_lowpass_filter(x_) \n",
    "\n",
    "        if self.apply_mu_law_encoding:\n",
    "            x_ = self._quantize_data(x_, 1)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            x_ = x_[::self.downsample, :]\n",
    "\n",
    "        return x_\n",
    "\n",
    "    def _apply_chris_magic_ch8(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Generate features based on Chris' magic formula.\"\"\" \n",
    "        x_tmp = np.zeros((EEG_PTS, self.n_feats), dtype=\"float32\")\n",
    "\n",
    "        # Generate features\n",
    "        x_tmp[:, 0] = x[:, self.FEAT2CODE[\"Fp1\"]] - x[:, self.FEAT2CODE[\"T3\"]]\n",
    "        x_tmp[:, 1] = x[:, self.FEAT2CODE[\"T3\"]] - x[:, self.FEAT2CODE[\"O1\"]]\n",
    "        \n",
    "        x_tmp[:, 2] = x[:, self.FEAT2CODE[\"Fp1\"]] - x[:, self.FEAT2CODE[\"C3\"]]\n",
    "        x_tmp[:, 3] = x[:, self.FEAT2CODE[\"C3\"]] - x[:, self.FEAT2CODE[\"O1\"]]\n",
    "        \n",
    "        x_tmp[:, 4] = x[:, self.FEAT2CODE[\"Fp2\"]] - x[:, self.FEAT2CODE[\"C4\"]]\n",
    "        x_tmp[:, 5] = x[:, self.FEAT2CODE[\"C4\"]] - x[:, self.FEAT2CODE[\"O2\"]]\n",
    "        \n",
    "        x_tmp[:, 6] = x[:, self.FEAT2CODE[\"Fp2\"]] - x[:, self.FEAT2CODE[\"T4\"]]\n",
    "        x_tmp[:, 7] = x[:, self.FEAT2CODE[\"T4\"]] - x[:, self.FEAT2CODE[\"O2\"]]\n",
    "\n",
    "        return x_tmp\n",
    "\n",
    "    def _butter_lowpass_filter(self, data, cutoff_freq=20, sampling_rate=200, order=4):\n",
    "        nyquist = 0.5 * sampling_rate\n",
    "        normal_cutoff = cutoff_freq / nyquist\n",
    "        b, a = butter(order, normal_cutoff, btype=\"low\", analog=False)\n",
    "        filtered_data = lfilter(b, a, data, axis=0)\n",
    "\n",
    "        return filtered_data\n",
    "                \n",
    "    def _quantize_data(self, data, classes):\n",
    "        mu_x = self._mu_law_encoding(data, classes)\n",
    "        \n",
    "        return mu_x\n",
    "\n",
    "    def _mu_law_encoding(self, data, mu):\n",
    "        mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n",
    "\n",
    "        return mu_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    \"\"\"Dataset for pure raw EEG signals.\n",
    "\n",
    "    Args:\n",
    "        data: processed data\n",
    "        split: data split\n",
    "\n",
    "    Attributes:\n",
    "        _n_samples: number of samples\n",
    "        _infer: if True, the dataset is constructed for inference\n",
    "            *Note: Ground truth is not provided.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: Dict[str,  Any],\n",
    "        split: str,\n",
    "        **dataset_cfg: Any,\n",
    "    ) -> None:\n",
    "        self.metadata = data[\"meta\"]\n",
    "        self.all_eegs = data[\"eeg\"]\n",
    "        self.dataset_cfg = dataset_cfg\n",
    "\n",
    "        # Raw EEG data transformer\n",
    "        self.eeg_params = dataset_cfg[\"eeg\"]\n",
    "        self.eeg_trafo = _EEGTransformer(**self.eeg_params)\n",
    "\n",
    "        self._set_n_samples()\n",
    "        self._infer = True if split == \"test\" else False\n",
    "\n",
    "        self._stream_X = True if self.all_eegs is None else False\n",
    "        self._X, self._y = self._transform()\n",
    "\n",
    "    def _set_n_samples(self) -> None:\n",
    "        assert len(self.metadata) == self.metadata[\"eeg_id\"].nunique()\n",
    "        self._n_samples = len(self.metadata)\n",
    "\n",
    "    def _transform(self) -> Tuple[Optional[np.ndarray], np.ndarray]:\n",
    "        \"\"\"Transform feature and target matrices.\"\"\"\n",
    "        if self.eeg_params[\"downsample\"] is not None:\n",
    "            eeg_len = int(EEG_PTS / self.eeg_params[\"downsample\"])\n",
    "        else:\n",
    "            eeg_len = int(EEG_PTS)\n",
    "        if not self._stream_X:\n",
    "            X = np.zeros((self._n_samples, eeg_len, self.eeg_params[\"n_feats\"]), dtype=\"float32\")\n",
    "        else:\n",
    "            X = None\n",
    "        y = np.zeros((self._n_samples, N_CLASSES), dtype=\"float32\") if not self._infer else None\n",
    "\n",
    "        for i, row in tqdm(self.metadata.iterrows(), total=len(self.metadata)):\n",
    "            # Process raw EEG signals\n",
    "            if not self._stream_X:\n",
    "                # Retrieve raw EEG signals\n",
    "                eeg = self.all_eegs[row[\"eeg_id\"]]\n",
    "\n",
    "                # Apply EEG transformer\n",
    "                x = self.eeg_trafo.transform(eeg)\n",
    "\n",
    "                X[i] = x\n",
    "\n",
    "            if not self._infer:\n",
    "                y[i] = row[TGT_VOTE_COLS] \n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self._n_samples\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, Tensor]:\n",
    "        if self._X is None:\n",
    "            # Load data here...\n",
    "#             x = np.load(...)\n",
    "#             x = self.eeg_trafo.transform(x)\n",
    "            pass\n",
    "        else:\n",
    "            x = self._X[idx, ...]\n",
    "        data_sample = {\"x\": torch.tensor(x, dtype=torch.float32)}\n",
    "        if not self._infer:\n",
    "            data_sample[\"y\"] = torch.tensor(self._y[idx, :], dtype=torch.float32)\n",
    "\n",
    "        return data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Train and Eval Process - Fold0 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly. Reconnecting the current kernel may help.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c452382bd02f44d4a3d69bd9ec909821"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'FloatProgress' object has no attribute 'style'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;66;03m# Build dataloaders\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         data_tr, data_val \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39miloc[tr_idx]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), train\u001b[38;5;241m.\u001b[39miloc[val_idx]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m         train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m---> 12\u001b[0m             \u001b[43mEEGDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_eegs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     13\u001b[0m             shuffle\u001b[38;5;241m=\u001b[39mCFG\u001b[38;5;241m.\u001b[39mtrainer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshuffle\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     14\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39mCFG\u001b[38;5;241m.\u001b[39mtrainer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     15\u001b[0m             num_workers\u001b[38;5;241m=\u001b[39mCFG\u001b[38;5;241m.\u001b[39mtrainer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_workers\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     16\u001b[0m         )\n\u001b[1;32m     17\u001b[0m         val_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     18\u001b[0m             EEGDataset({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m: data_val, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meeg\u001b[39m\u001b[38;5;124m\"\u001b[39m: all_eegs}, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mCFG\u001b[38;5;241m.\u001b[39mdataset),\n\u001b[1;32m     19\u001b[0m             shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39mCFG\u001b[38;5;241m.\u001b[39mtrainer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     21\u001b[0m             num_workers\u001b[38;5;241m=\u001b[39mCFG\u001b[38;5;241m.\u001b[39mtrainer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_workers\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     22\u001b[0m         )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m, in \u001b[0;36mEEGDataset.__init__\u001b[0;34m(self, data, split, **dataset_cfg)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_eegs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 50\u001b[0m, in \u001b[0;36mEEGDataset._transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     48\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_samples, N_CLASSES), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# Process raw EEG signals\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream_X:\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;66;03m# Retrieve raw EEG signals\u001b[39;00m\n\u001b[1;32m     54\u001b[0m         eeg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_eegs[row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meeg_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/notebook.py:241\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplay\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolour\u001b[49m \u001b[38;5;241m=\u001b[39m colour\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# Print initial bar state\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/notebook.py:200\u001b[0m, in \u001b[0;36mtqdm_notebook.colour\u001b[0;34m(self, bar_color)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;129m@colour\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcolour\u001b[39m(\u001b[38;5;28mself\u001b[39m, bar_color):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontainer\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 200\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[38;5;241m.\u001b[39mbar_color \u001b[38;5;241m=\u001b[39m bar_color\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FloatProgress' object has no attribute 'style'"
     ]
    }
   ],
   "source": [
    "        \n",
    "if CFG.train_models:\n",
    "    oof = np.zeros((len(train), N_CLASSES))\n",
    "    prfs = []\n",
    "\n",
    "    cv = GroupKFold(n_splits=5)\n",
    "    for fold, (tr_idx, val_idx) in enumerate(cv.split(train, train[TGT_COL], train[\"patient_id\"])):\n",
    "        logger.info(f\"== Train and Eval Process - Fold{fold} ==\")\n",
    "\n",
    "        # Build dataloaders\n",
    "        data_tr, data_val = train.iloc[tr_idx].reset_index(drop=True), train.iloc[val_idx].reset_index(drop=True)\n",
    "        train_loader = DataLoader(\n",
    "            EEGDataset({\"meta\": data_tr, \"eeg\": all_eegs}, \"train\", **CFG.dataset),\n",
    "            shuffle=CFG.trainer[\"dataloader\"][\"shuffle\"],\n",
    "            batch_size=CFG.trainer[\"dataloader\"][\"batch_size\"],\n",
    "            num_workers=CFG.trainer[\"dataloader\"][\"num_workers\"]\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            EEGDataset({\"meta\": data_val, \"eeg\": all_eegs}, \"valid\", **CFG.dataset),\n",
    "            shuffle=False,\n",
    "            batch_size=CFG.trainer[\"dataloader\"][\"batch_size\"],\n",
    "            num_workers=CFG.trainer[\"dataloader\"][\"num_workers\"]\n",
    "        )\n",
    "else:\n",
    "    file_path = DATA_PATH / \"kaggle/input/hms-oof-demo/oof_seed0.npy\"\n",
    "    print(f\"Checking file path: {file_path}\")\n",
    "    print(f\"File exists: {os.path.exists(file_path)}\")\n",
    "    oof = np.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
